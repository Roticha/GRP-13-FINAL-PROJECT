{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Flow â€“ Understanding Sentiments expressed on Twitter about Apple and Google Products using NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1. Business Understanding\n",
    "\n",
    "### 1.1 Introduction \n",
    "In an era where public opinion on products can shape brand perception, companies increasingly rely on Natural Language Processing (NLP) for real-time customer feedback analysis. This project, applies NLP techniques to classify Twitter sentiment related to Apple and Google products, addressing a real-world need for understanding public sentiment in a rapidly evolving market. By using sentiment polarity classification,it provides actionable insights into customer satisfaction and emerging issues, enabling companies, marketing teams, and decision-makers to make data-driven decisions. These insights help brands like Apple and Google improve products, refine customer support strategies, and optimize marketing efforts based on social media sentiment.\n",
    "\n",
    "\n",
    "### 1.2 Problem Statement\n",
    "The problem is to accurately classify the sentiment of tweets related to __Apple and Google products__. We want to determine whether a tweet expresses a positive, negative, or neutral sentiment. This classification can help companies understand customer satisfaction, identify potential issues, and tailor their responses accordingly.\n",
    "\n",
    "### 1.3 Stakeholders \n",
    "- __The companies__: Apple & Google- Considering these companies are direcly affected by the sentiment, it is important for them to gauge the perception of their products so as to identify the areas of improvement.\n",
    "\n",
    "- __Marketing teams__- this sentiment analysis and model can help them respond to negative feedback, adjust their marketing campaigns and highlight the positive aspects of their products.\n",
    "\n",
    "- __The customer support teams &decision makers__- the sentiment analysis is important for they can use it to improve product development, customer support and brand reputation.\n",
    "\n",
    "### 1.4  Business Value\n",
    "By accurately classifying tweets, our NLP model provides actionable insights to stakeholders. For example:\n",
    "\n",
    "- Identifying negative sentiment can help companies address issues promptly.\n",
    "- Recognizing positive sentiment can guide marketing efforts and reinforce successful strategies.\n",
    "- Understanding neutral sentiment can provide context and balance.\n",
    "\n",
    "### 1.5 Objectives \n",
    "Main Objective\n",
    "\n",
    "To develop a NLP (Natural Language Processing) multiclass classification model for sentiment analysis, aim to achieve a __recall score of 80%__ and an __accuracy of 80%__. The model should categorize sentiments into three classes: __Positive__, __Negative__, and __Neutral__.\n",
    "\n",
    "Specific Objectives\n",
    "\n",
    "- To idenitfy the most common words used in the dataset using Word cloud.\n",
    "\n",
    "- To confirm the most common words that are positively and negatively tagged.\n",
    "\n",
    "- To recognize the products that have been opined by the users.\n",
    "\n",
    "- To spot the distribution of the sentiments.\n",
    "\n",
    "### 1.6 Conclusion \n",
    "Our NLP model will contribute valuable insights to the real-world problem of understanding Twitter sentiment about Apple and Google products. Stakeholders can leverage this information to enhance their decision-making processes and improve overall customer satisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Understanding\n",
    "\n",
    "### 2.1 Data source\n",
    "The dataset originates from __CrowdFlower via data.world__. Contributors evaluated tweets related to various brands and products. Specifically:\n",
    "\n",
    "- Each tweet was labeled as expressing __positive__, __negative__, __no emotion__ or __can't tell__ toward a brand or product.\n",
    "- If emotion was expressed, contributors specified which brand or product was the target.\n",
    "\n",
    "### 2.2 Suitability of the Data\n",
    "Here's why this dataset is suitable for our project:\n",
    "\n",
    "- __Relevance__: The data directly aligns with our business problem of understanding Twitter sentiment for Apple and Google products.\n",
    "- __Real-World Context__: The tweets represent actual user opinions, making the problem relevant in practice.\n",
    "- __Multiclass Labels__: We can build both binary (positive/negative) and multiclass (positive/negative/neutral) classifiers using this data.\n",
    "\n",
    "### 2.3 Dataset Size\n",
    "The dataset contains __over 9,000 labeled tweets__. We'll explore its features to gain insights.\n",
    "\n",
    "### 2.4 Descriptive Statistics\n",
    "- __tweet_text__: The content of each tweet.\n",
    "- __is_there_an_emotion_directed_at_a_brand_or_product__: No emotion toward brand or product, Positive emotion, Negative emotion, I can't tell\n",
    "- __emotion_in_tweet_is_directed_at__: The brand or product mentioned in the tweet.\n",
    "\n",
    "### 2.5 Feature Selection\n",
    "__Tweet text__ is the primary feature. The emotion label and target brand/product are essential for classification.\n",
    "\n",
    "### 2.6 Data Limitations\n",
    "- __Label Noise__: Human raters' subjectivity may introduce noise.\n",
    "- __Imbalanced Classes__: We'll address class imbalance during modeling.\n",
    "- __Contextual Challenges__: Tweets are often short and context-dependent.\n",
    "- __Incomplete & Missing Data__: Could affect the overall performance of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading\n",
    "\n",
    "### 3.1 Importing Necessary Modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# nltk\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, recall_score\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# wordCloud\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# pickle\n",
    "import pickle\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading dataset\n",
    "\n",
    "file_path = r\"C:\\Users\\PC\\Documents\\Flatiron\\dsc-data-science-env-config\\Phase_5_capstone_project\\judge_tweet_product_company.csv\"\n",
    "# Our dataset contains special characters or a non-standard encoding.\n",
    "# We solved this by reading the file using different encoding \"ISO-8859-1\"\n",
    "data= pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\n",
      "----\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Checking data information\n",
    "print(\"INFO\")\n",
    "print(\"-\" * 4)\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (9093, 3)\n",
      "Number of Rows: 9093\n",
      "Number of Columns: 3\n"
     ]
    }
   ],
   "source": [
    "# Find the shape of the DataFrame\n",
    "data_shape = data.shape\n",
    "\n",
    "# Print the shape\n",
    "print(\"Data Shape:\", data_shape)\n",
    "print(\"Number of Rows:\", data_shape[0])\n",
    "print(\"Number of Columns:\", data_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UNIQUE VALUES\n",
      "------------\n",
      "Column *tweet_text* has 9065 unique values\n",
      "\n",
      "Column *emotion_in_tweet_is_directed_at* has 9 unique values\n",
      "Top unique values in the *emotion_in_tweet_is_directed_at* include:\n",
      "- iPad\n",
      "- Apple\n",
      "- iPad or iPhone App\n",
      "- Google\n",
      "- iPhone\n",
      "- Other Google product or service\n",
      "- Android App\n",
      "- Android\n",
      "- Other Apple product or service\n",
      "\n",
      "Column *is_there_an_emotion_directed_at_a_brand_or_product* has 4 unique values\n",
      "Top unique values in the *is_there_an_emotion_directed_at_a_brand_or_product* include:\n",
      "- No emotion toward brand or product\n",
      "- Positive emotion\n",
      "- Negative emotion\n",
      "- I can't tell\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Unique Values\n",
    "print(\"\\n\\nUNIQUE VALUES\")\n",
    "print(\"-\" * 12)\n",
    "for col in data.columns:\n",
    "    print(f\"Column *{col}* has {data[col].nunique()} unique values\")\n",
    "    if data[col].nunique() < 12:\n",
    "        print(f\"Top unique values in the *{col}* include:\")\n",
    "        for idx in data[col].value_counts().index:\n",
    "            print(f\"- {idx}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MISSING VALUES\n",
      "---------------\n",
      "Column *tweet_text* has 1 missing values.\n",
      "Column *emotion_in_tweet_is_directed_at* has 5802 missing values.\n",
      "Column *is_there_an_emotion_directed_at_a_brand_or_product* has 0 missing values.\n"
     ]
    }
   ],
   "source": [
    "# Missing or Null Values\n",
    "print(\"\\nMISSING VALUES\")\n",
    "print(\"-\" * 15)\n",
    "for col in data.columns:\n",
    "    print(f\"Column *{col}* has {data[col].isnull().sum()} missing values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate Values\n",
    "print(\"\\n\\nDUPLICATE VALUES\")\n",
    "print(\"-\" * 16)\n",
    "print(f\"The dataset has {data.duplicated().sum()} duplicated records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments:\n",
    "\n",
    "1. All the columns are in the correct data types.\n",
    "\n",
    "2. The columns will need to be renamed.\n",
    "\n",
    "3. Features with missing values should be renamed from NaN.\n",
    "\n",
    "4. Duplicate records should be dropped.\n",
    "\n",
    "5. All records with the target as \"I can't tell\" should be dropped.\n",
    "\n",
    "6. Corrupted records should be removed.\n",
    "\n",
    "7. Rename values in the is_there_an_emotion_directed_at_a_brand_or_product where the value is 'No emotion toward brand or product' to 'Neutral Emotion'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Data Cleaning & Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Checking the validity of data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 Corrupted data at the *tweet_text* column\n",
    "There may be an issue of corrupted data in some records. To address this, we create a function that identifies these records and returns their indexes. Corrupted data often includes non-ASCII characters, which may indicate unexpected special symbols, foreign language characters, or encoding issues that do not fit the expected data format. Detecting and removing these records is especially important when working with systems or processes that support only ASCII characters, as non-ASCII characters can cause errors or misinterpretations. By using the identified indexes, we can remove the corrupted records from the working DataFrame, ensuring consistency and compatibility in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function targeting corrupted records\n",
    "def is_corrupted(tweet):\n",
    "    \"\"\"This func returns the index of any record that is corrupted\"\"\"\n",
    "    corrupted_cols = []\n",
    "    for key, text in enumerate(tweet):\n",
    "        if any(ord(char) > 127 for char in str(text)) == True:\n",
    "            corrupted_cols.append(key)\n",
    "    return corrupted_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the is_corrupted function to find the indexes of the corrupted records\n",
    "corrupted_records_idx = is_corrupted(data['tweet_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@mention  - False Alarm: Google Circles Not Coming NowÂ‰Ã›Ã’and Probably Not Ever? - {link} #Google #Circles #Social #SXSW\n"
     ]
    }
   ],
   "source": [
    "# Test to check if the function worked as intended\n",
    "if not data.loc[corrupted_records_idx].empty:\n",
    "    tweet_text = data.loc[corrupted_records_idx]['tweet_text'].values[0]\n",
    "    print(tweet_text)\n",
    "else:\n",
    "    print(\"No corrupted records found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop these records\n",
    "data.drop(index=corrupted_records_idx, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test to ensure there are no corrupted records left\n",
    "is_corrupted(data['tweet_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 Remove records in the *is_there_an_emotion_directed_at_a_brand_or_product* column where the value is \"I can't tell.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [tweet_text, emotion_in_tweet_is_directed_at, is_there_an_emotion_directed_at_a_brand_or_product]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify records with the specified value\n",
    "uncertain_reaction_idx = data[data['is_there_an_emotion_directed_at_a_brand_or_product'] == \"I can't tell\"].index\n",
    "\n",
    "# Remove the identified records\n",
    "data.drop(index=uncertain_reaction_idx, inplace=True)\n",
    "\n",
    "# Test & verify removal\n",
    "data[data['is_there_an_emotion_directed_at_a_brand_or_product'] == \"I can't tell\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3 Replace Fields in the *is_there_an_emotion_directed_at_a_brand_or_product* column where the value is \"No emotion toward brand or product\" to \"Neutral emotion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [tweet_text, emotion_in_tweet_is_directed_at, is_there_an_emotion_directed_at_a_brand_or_product]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify records with the specified value\n",
    "neutral_reaction_idx = data[data['is_there_an_emotion_directed_at_a_brand_or_product'] ==\\\n",
    "                              \"No emotion toward brand or product\"].index\n",
    "\n",
    "# Remove the identified records\n",
    "data.loc[neutral_reaction_idx, 'is_there_an_emotion_directed_at_a_brand_or_product'] = \"Neutral emotion\"\n",
    "\n",
    "# Test & verify the removal\n",
    "data[data['is_there_an_emotion_directed_at_a_brand_or_product'] == \"No emotion toward brand or product\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Completeness of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Drop Missing Values in the *tweet_text* column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tweet_text emotion_in_tweet_is_directed_at  \\\n",
       "6        NaN                             NaN   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "6                                    Neutral emotion  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_missing = data[data['tweet_text'].isnull() == True].index\n",
    "data.loc[tweet_missing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the record\n",
    "data.drop(index=tweet_missing, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [tweet_text, emotion_in_tweet_is_directed_at, is_there_an_emotion_directed_at_a_brand_or_product]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test & verify removal\n",
    "data[data['tweet_text'].isnull() == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Fill Missing Values in the *emotion_in_tweet_is_directed_at* column\n",
    "This column has over 5000 missing values. This means that a tweet may have been written but the product not identified.  The best cause of action is to take missing values in *emotion_in_tweet_is_directed_at* and attempt to fill them based on the content of the tweet by identifying which product (if any) the tweet is directed at. If a product is not identified, it is assigned the unique value 'None' instead of dropping the rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5331"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the records with missing values in the column\n",
    "data[data['emotion_in_tweet_is_directed_at'].isnull() == True].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of unique products/ services\n",
    "products = list(data.emotion_in_tweet_is_directed_at.unique())\n",
    "products.remove(np.nan) # Removes any np.nan items\n",
    "\n",
    "def find_product(tweet):\n",
    "    \"\"\"This func takes in a tweet and returns the product talked about in the\n",
    "    tweet; used to fill in the emotion_in_tweet_is_directed_at column\"\"\"\n",
    "    for product in products:\n",
    "        if str(product) in tweet or str(product).upper() in tweet \\\n",
    "            or  str(product).lower() in tweet or str(product).title() in tweet:\n",
    "            return product\n",
    "\n",
    "# Applying the function to find the index of records with missing values in the 2nd column\n",
    "missing_products_idx = data[data['emotion_in_tweet_is_directed_at'].isnull() == True].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the field where there are missing values in the emotion_in_tweet_is_directed_at column\n",
    "data.loc[missing_products_idx, 'emotion_in_tweet_is_directed_at'] = data.loc[missing_products_idx, 'tweet_text']\\\n",
    "                                                                        .apply(lambda x: find_product(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case any field was not captured by our function, we can change it to 'None'\n",
    "none_index = data[data['emotion_in_tweet_is_directed_at'].isnull()].index\n",
    "data.loc[none_index, 'emotion_in_tweet_is_directed_at'] = 'None'\n",
    "# df.loc[none_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iPad                               2273\n",
       "Google                             1984\n",
       "Apple                              1269\n",
       "iPhone                             1093\n",
       "None                                720\n",
       "iPad or iPhone App                  448\n",
       "Android                             284\n",
       "Other Google product or service     278\n",
       "Android App                          77\n",
       "Other Apple product or service       33\n",
       "Name: emotion_in_tweet_is_directed_at, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check\n",
    "data['emotion_in_tweet_is_directed_at'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of values in the column are the same as the length of the data\n",
    "np.sum(data['emotion_in_tweet_is_directed_at'].value_counts().values) == data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: We were able to assign all tweets to a product and only 720 were not talking about a product explicitly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Consistency : Dropping the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the duplicates\n",
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there is any remaining duplicate values\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Uniformity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.1 Renaming the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the column names\n",
    "data.rename(columns={'tweet_text': \"tweet\",\n",
    "                  'emotion_in_tweet_is_directed_at':\"product\",\n",
    "                  'is_there_an_emotion_directed_at_a_brand_or_product': \"emotion\"},\n",
    "         inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet', 'product', 'emotion'], dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.2 Reset the Index of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>product</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet             product  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "            emotion  \n",
       "0  Negative emotion  \n",
       "1  Positive emotion  \n",
       "2  Positive emotion  \n",
       "3  Negative emotion  \n",
       "4  Positive emotion  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset the index\n",
    "data.reset_index(inplace=True)\n",
    "# Drop the old index column\n",
    "data.drop(labels='index', axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Data Cleaning / Feature Engineering result\n",
    "This is to verify the cleaning and feature engineering process worked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO\n",
      "----\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8439 entries, 0 to 8438\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   tweet    8439 non-null   object\n",
      " 1   product  8439 non-null   object\n",
      " 2   emotion  8439 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 197.9+ KB\n",
      "None\n",
      "\n",
      "SHAPE\n",
      "-----\n",
      "Records in dataset are 8439 with 3 columns.\n",
      "\n",
      "COLUMNS\n",
      "------\n",
      "Columns in the dataset are:\n",
      "- tweet\n",
      "- product\n",
      "- emotion\n",
      "\n",
      "UNIQUE VALUES\n",
      "------------\n",
      "Column *tweet* has 8434 unique values\n",
      "Column *product* has 10 unique values\n",
      "Top unique values in the *product* include:\n",
      "- iPad\n",
      "- Google\n",
      "- Apple\n",
      "- iPhone\n",
      "- None\n",
      "- iPad or iPhone App\n",
      "- Android\n",
      "- Other Google product or service\n",
      "- Android App\n",
      "- Other Apple product or service\n",
      "Column *emotion* has 3 unique values\n",
      "Top unique values in the *emotion* include:\n",
      "- Neutral emotion\n",
      "- Positive emotion\n",
      "- Negative emotion\n",
      "\n",
      "MISSING VALUES\n",
      "---------------\n",
      "Column *tweet* has 0 missing values.\n",
      "Column *product* has 0 missing values.\n",
      "Column *emotion* has 0 missing values.\n",
      "\n",
      "DUPLICATE VALUES\n",
      "----------------\n",
      "The dataset has 0 duplicated records.\n"
     ]
    }
   ],
   "source": [
    "# INFO\n",
    "print(\"INFO\")\n",
    "print(\"----\")\n",
    "print(data.info())\n",
    "\n",
    "# SHAPE\n",
    "print(\"\\nSHAPE\")\n",
    "print(\"-----\")\n",
    "print(f\"Records in dataset are {data.shape[0]} with {data.shape[1]} columns.\")\n",
    "\n",
    "# COLUMNS\n",
    "print(\"\\nCOLUMNS\")\n",
    "print(\"------\")\n",
    "print(\"Columns in the dataset are:\")\n",
    "for col in data.columns:\n",
    "    print(f\"- {col}\")\n",
    "\n",
    " # UNIQUE VALUES\n",
    "print(\"\\nUNIQUE VALUES\")\n",
    "print(\"------------\")\n",
    "for col in data.columns:\n",
    "    unique_values = data[col].nunique()\n",
    "    print(f\"Column *{col}* has {unique_values} unique values\")\n",
    "    if col == 'product' or col == 'emotion': \n",
    "        top_values = data[col].value_counts().index[:10].tolist()\n",
    "        print(f\"Top unique values in the *{col}* include:\")\n",
    "        for val in top_values:\n",
    "            print(f\"- {val}\")\n",
    "\n",
    "# MISSING VALUES\n",
    "print(\"\\nMISSING VALUES\")\n",
    "print(\"---------------\")\n",
    "for col in data.columns:\n",
    "    missing_values = data[col].isnull().sum()\n",
    "    print(f\"Column *{col}* has {missing_values} missing values.\")\n",
    "\n",
    "# DUPLICATE VALUES\n",
    "print(\"\\nDUPLICATE VALUES\")\n",
    "print(\"----------------\")\n",
    "duplicate_count = data.duplicated().sum()\n",
    "print(f\"The dataset has {duplicate_count} duplicated records.\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
